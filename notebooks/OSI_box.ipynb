{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from varyingsim.osi import OSI\n",
    "from varyingsim.box import BoxEnv\n",
    "from varyingsim.util.buffers import TrajBuffer\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we will train the OSI and prediction models disjointly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_traj = 20\n",
    "n_val = 5\n",
    "T = 2000\n",
    "h = 16\n",
    "shapes = [(2,)] * 5 + [()] # qpos, qvel, prevqpos, prevqvel, action, friction\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_to_datum(obs, prev_obs, a):\n",
    "    \"\"\"\n",
    "    obs is qpos, qvel, box fric, floor fric, mass, gear\n",
    "    \"\"\"\n",
    "    xy = obs[0:2]\n",
    "    xy_vel = obs[3:5]\n",
    "    xy_prev = prev_obs[0:2]\n",
    "    xy_vel_prev = prev_obs[3:5]\n",
    "    friction = prev_obs[7] # TODO: should this be previous?\n",
    "    act = np.array(a)\n",
    "\n",
    "    return xy, xy_vel, xy_prev, xy_vel_prev, act, friction \n",
    "\n",
    "def get_data(env, buffer, T):\n",
    "    obs = env.reset()\n",
    "    t = 0\n",
    "    scale = 100\n",
    "    \n",
    "    buffer.set_new_traj()\n",
    "    while t < T:\n",
    "        a = [np.sin(t / scale), np.cos(t / scale)] # we should do someting more sophisticated\n",
    "        prev_obs = obs\n",
    "        obs, rew, done, info = env.step(a)\n",
    "        datum = obs_to_datum(obs, prev_obs, a)\n",
    "        buffer.add_datum(datum)\n",
    "        t += 1\n",
    "\n",
    "def buffer_to_osi_torch(batch):\n",
    "    \"\"\"\n",
    "        takes in a batch from a TrajBuffer and returns a pytorch batch\n",
    "        of size N x h x d_in\n",
    "    \"\"\"\n",
    "    N, h, _ = batch[0].shape\n",
    "\n",
    "    x = np.concatenate([batch[0], batch[1]], axis=-1) # history of xy, xy_vel\n",
    "    y = batch[-1][:, -1] # latest friciton\n",
    "\n",
    "    x_torch = torch.from_numpy(x).float()\n",
    "    y_torch = torch.from_numpy(y).float().unsqueeze(-1)\n",
    "\n",
    "    return x_torch, y_torch\n",
    "\n",
    "def set_friction_sin(env, t, scale=213):\n",
    "    env.set_floor_friction(np.sin(t / scale) * 0.15 + 1.15)\n",
    "\n",
    "def set_friction_step(env, t, scale=50):\n",
    "    if t // scale % 2 == 0:\n",
    "        env.set_floor_friction(1.0)\n",
    "    else:\n",
    "        env.set_floor_friction(1.3)\n",
    "\n",
    "def visual_eval(buffer, model, h, device='cuda'):\n",
    "    val_batch = val_buffer.get_traj_batch(4, h)\n",
    "    x, y = buffer_to_osi_torch(val_batch)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_hat = model(x) \n",
    "    print(y_hat)\n",
    "    print(y)\n",
    "\n",
    "def eval(buffer, model, h, device='cuda'):\n",
    "    # TODO: should have a method that just returns all trajectories concated\n",
    "    val_batch = val_buffer.get_traj_batch(len(buffer), h)\n",
    "    x, y = buffer_to_osi_torch(val_batch)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_hat = model(x) \n",
    "    loss = F.mse_loss(y_hat, y)\n",
    "    return loss.item()\n",
    "\n",
    "def train_osi(env, train_buffer, val_buffer, h):\n",
    "    d_in = env.model.nq - 1 + env.model.nu # xvel, yvel, and action\n",
    "    d_param = 1 # just friciton for now\n",
    "    d_hidden_shared = 64\n",
    "    d_hidden_osi = 256\n",
    "\n",
    "    model = OSI(h, d_in, d_param, d_hidden_shared, d_hidden_osi)\n",
    "    \n",
    "    lr = 1e-3\n",
    "    batch_size = 64\n",
    "    n_iters = 6000\n",
    "    print_iter = 50\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for i in range(n_iters):\n",
    "        batch = train_buffer.get_traj_batch(batch_size, h)\n",
    "        x, y = buffer_to_osi_torch(batch)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optim.zero_grad()\n",
    "        y_hat = model(x)\n",
    "\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if i % print_iter == 0:\n",
    "            val_batch = val_buffer.get_traj_batch(128, h)\n",
    "            x_val, y_val = buffer_to_osi_torch(val_batch)\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            y_hat_val = model(x_val)\n",
    "            val_loss = F.mse_loss(y_hat_val, y_val)\n",
    "            print(i, loss.item(), val_loss.item())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BoxEnv(set_param_fn=set_friction_sin, rand_reset=True)\n",
    "\n",
    "train_buffer = TrajBuffer(-1, shapes)\n",
    "val_buffer = TrajBuffer(-1, shapes)\n",
    "\n",
    "for i in range(n_traj):\n",
    "    get_data(env, train_buffer, T)\n",
    "for i in range(n_val):\n",
    "    get_data(env, val_buffer, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.3349215984344482 0.6299585103988647\n",
      "50 0.006848664488643408 0.00786968320608139\n",
      "100 0.004041353706270456 0.003887791885063052\n",
      "150 0.0028496631421148777 0.0027191087137907743\n",
      "200 0.0011799049098044634 0.0013772605452686548\n",
      "250 0.0008055281941778958 0.0007930191932246089\n",
      "300 0.0008958268444985151 0.0006273123435676098\n",
      "350 0.00042417208896949887 0.0005331055726855993\n",
      "400 0.0005236775032244623 0.0009426895412616432\n",
      "450 0.0005248639499768615 0.000687066582031548\n",
      "500 0.00041864762897603214 0.0004596546641550958\n",
      "550 0.0004536719061434269 0.000613196287304163\n",
      "600 0.00042437613592483103 0.0006377086974680424\n",
      "650 0.0003540627076290548 0.0004107936401851475\n",
      "700 0.00037777257966808975 0.0004533175379037857\n",
      "750 0.0004513421154115349 0.0003319201641716063\n",
      "800 0.0003512442926876247 0.0008016062201932073\n",
      "850 0.0004514720058068633 0.00032077389187179506\n",
      "900 0.00026805768720805645 0.00030641138437204063\n",
      "950 0.00039958395063877106 0.0005286566447466612\n",
      "1000 0.00033376069040969014 0.0005572964437305927\n",
      "1050 0.0003783107385970652 0.0003820338752120733\n",
      "1100 0.000444740173406899 0.0005312648136168718\n",
      "1150 0.00019074740703217685 0.00026630720822140574\n",
      "1200 0.00038681126898154616 0.00037500663893297315\n",
      "1250 0.00026932184118777514 0.0005036763031966984\n",
      "1300 0.00035890290746465325 0.0005051422631368041\n",
      "1350 0.0004888540715910494 0.0002701577905099839\n",
      "1400 0.0004569765296764672 0.00024959162692539394\n",
      "1450 0.0003205139946658164 0.0003087215591222048\n",
      "1500 0.0001882860087789595 0.0004092407471034676\n",
      "1550 0.00048244569916278124 0.00040014495607465506\n",
      "1600 0.0003359709517098963 0.0006811575149185956\n",
      "1650 0.0002783988893497735 0.0005049424362368882\n",
      "1700 0.00040369993075728416 0.00023355864686891437\n",
      "1750 0.00025298199034295976 0.0004866823146585375\n",
      "1800 0.0002941525599453598 0.00025669432943686843\n",
      "1850 0.0007214501965790987 0.00025763886515051126\n",
      "1900 0.0002637592260725796 0.00033794427872635424\n",
      "1950 0.00022257644741330296 0.00029395829187706113\n",
      "2000 0.00032774085411801934 0.0005140278954058886\n",
      "2050 0.0005549330962821841 0.0003676410997286439\n",
      "2100 0.00029868452111259103 0.0002916142111644149\n",
      "2150 0.00039065550663508475 0.000489546568132937\n",
      "2200 0.00021482628653757274 0.0007762579480186105\n",
      "2250 0.0003667192067950964 0.00020182639127597213\n",
      "2300 0.0002917333913501352 0.0002673879498615861\n",
      "2350 0.00022022018674761057 0.0003149844706058502\n",
      "2400 0.0005968474433757365 0.00026897384668700397\n",
      "2450 0.0004618834354914725 0.00025378871941938996\n",
      "2500 0.00035775129799731076 0.00035017746267840266\n",
      "2550 0.0004022017237730324 0.00030427309684455395\n",
      "2600 0.00028087489772588015 0.00025668885791674256\n",
      "2650 0.00028292060596868396 0.000260757515206933\n",
      "2700 0.00033241749042645097 0.0006722856778651476\n",
      "2750 0.00027951825177296996 0.00041640576091594994\n",
      "2800 0.00013288925401866436 0.0002992766385432333\n",
      "2850 0.0005076928064227104 0.00020862188830506057\n",
      "2900 0.0002887857845053077 0.00037902811891399324\n",
      "2950 0.0004694173694588244 0.0007785375928506255\n",
      "3000 8.715281001059338e-05 0.00025516224559396505\n",
      "3050 0.00035993068013340235 0.00020437838975340128\n",
      "3100 0.00017567005124874413 0.00023566129675600678\n",
      "3150 0.0001440848282072693 0.0001873639994300902\n",
      "3200 0.0005642126780003309 0.0003954259736929089\n",
      "3250 0.0002054900978691876 0.0002007363800657913\n",
      "3300 0.0003401604772079736 0.0001474173623137176\n",
      "3350 0.0002596492995508015 0.0002521448186598718\n",
      "3400 0.00013628246961161494 0.0001654066436458379\n",
      "3450 0.00023743453493807465 0.00025254959473386407\n",
      "3500 0.000196458597201854 0.00015310768503695726\n",
      "3550 0.0001370851241517812 0.00019332482770550996\n",
      "3600 0.00024244296946562827 0.0002863357658497989\n",
      "3650 8.261651964858174e-05 0.00020196927653159946\n",
      "3700 0.00015121864271350205 0.00010430302063468844\n",
      "3750 8.95700286491774e-05 0.00030621609766967595\n",
      "3800 0.00029235027614049613 0.0002545946917962283\n",
      "3850 9.40131867537275e-05 0.00010702223517000675\n",
      "3900 0.00017298839520663023 0.0001861192868091166\n",
      "3950 0.0002440754178678617 0.0006571736303158104\n",
      "4000 0.00011045519931940362 0.00013877610035706311\n",
      "4050 0.0001619990507606417 0.00027297274209558964\n",
      "4100 0.00022000214084982872 0.00021236705651972443\n",
      "4150 0.00041267406777478755 0.00013404476339928806\n",
      "4200 0.00013573892647400498 0.00016578237409703434\n",
      "4250 0.0001189241447718814 0.0002083608414977789\n",
      "4300 0.0001322352618444711 0.00022349981009028852\n",
      "4350 0.00023401636281050742 0.00045894505456089973\n",
      "4400 0.00011030166933778673 0.00010546801058808342\n",
      "4450 0.00015802166308276355 0.00015936409181449562\n",
      "4500 0.0001668766635702923 0.0001540915691293776\n",
      "4550 0.00012794387293979526 0.00015587771486025304\n",
      "4600 0.00010489224223420024 0.00010092294542118907\n",
      "4650 9.062902245204896e-05 0.0001586062426213175\n",
      "4700 0.0003113329003099352 9.987049270421267e-05\n",
      "4750 0.0001296821574214846 0.00020379203488118947\n",
      "4800 9.913710528053343e-05 0.00024131749523803592\n",
      "4850 0.0001477168407291174 0.00019078594050370157\n",
      "4900 9.65679791988805e-05 8.175501716323197e-05\n",
      "4950 0.00016102484369184822 0.00015417452959809452\n",
      "5000 0.000360698439180851 0.0004297583072911948\n",
      "5050 0.0001248815970029682 0.0002871168253477663\n",
      "5100 0.00020290250540710986 0.00011966047168243676\n",
      "5150 0.00018286480917595327 0.00010535753244766966\n",
      "5200 0.00010305675095878541 0.00015281257219612598\n",
      "5250 0.00019125890685245395 0.0006419818964786828\n",
      "5300 0.00020570051856338978 0.00012163853534730151\n",
      "5350 5.604659236269072e-05 0.00012750377936754376\n",
      "5400 0.00016953711747191846 0.0001515416952315718\n",
      "5450 0.0001552589819766581 0.00012126509682275355\n",
      "5500 0.00044526392593979836 0.0005193496472202241\n",
      "5550 8.867163705872372e-05 0.0002213878178736195\n",
      "5600 0.0001671416248427704 0.0002255138533655554\n",
      "5650 0.00024163268972188234 0.00030508654890581965\n",
      "5700 8.807000995147973e-05 0.00011699562310241163\n",
      "5750 9.601521742297336e-05 0.00012078938016202301\n",
      "5800 9.956187568604946e-05 9.761384717421606e-05\n",
      "5850 8.641539898235351e-05 0.0001471236173529178\n",
      "5900 0.0001582428376423195 0.00016538164345547557\n",
      "5950 0.0002233655541203916 0.0001645123411435634\n",
      "0.00011140372225781903\n"
     ]
    }
   ],
   "source": [
    "osi_model = train_osi(env, train_buffer, val_buffer, h)\n",
    "eval_loss = eval(val_buffer, osi_model, h)\n",
    "print(eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traj_buffer_to_pred_torch(batch):\n",
    "    # qpos, qvel, prevqpos, prevqvel, action, friction\n",
    "    qpos = batch[0]\n",
    "    qvel = batch[1]\n",
    "    prev_qpos = batch[2]\n",
    "    prev_qvel = batch[3]\n",
    "    act = batch[4]\n",
    "    friction = batch[5]\n",
    "    x = np.concatenate([prev_qvel[:, -1], act[:, -1]], axis=-1)\n",
    "    y = np.concatenate([qpos[:, -1], qvel[:, -1]], axis=-1)\n",
    "    x_prev = np.concatenate([prev_qpos[:, -1], prev_qvel[:, -1]], axis=-1)\n",
    "    x_torch = torch.from_numpy(x).float()\n",
    "    y_torch = torch.from_numpy(y).float()\n",
    "    x_prev_torch = torch.from_numpy(x_prev).float()\n",
    "    friction_torch = torch.from_numpy(friction[:, -1]).unsqueeze(-1).float()\n",
    "    return x_torch, y_torch, x_prev_torch, friction_torch\n",
    "\n",
    "def batch_buffer_to_pred_torch(batch):\n",
    "    qpos = batch[0]\n",
    "    qvel = batch[1]\n",
    "    prev_qpos = batch[2]\n",
    "    prev_qvel = batch[3]\n",
    "    act = batch[4]\n",
    "    friction = batch[5]\n",
    "    x = np.concatenate([prev_qvel, act], axis=-1)\n",
    "    y = np.concatenate([qpos, qvel], axis=-1)\n",
    "    x_prev = np.concatenate([prev_qpos, prev_qvel], axis=-1)\n",
    "    x_torch = torch.from_numpy(x).float()\n",
    "    y_torch = torch.from_numpy(y).float()\n",
    "    x_prev_torch = torch.from_numpy(x_prev).float()\n",
    "    friction_torch = torch.from_numpy(friction).unsqueeze(-1).float()\n",
    "    return x_torch, y_torch, x_prev_torch, friction_torch\n",
    "\n",
    "def train_pred_model(train_buffer, val_buffer, include_friction=True):\n",
    "    d_in = 4 + include_friction # 2 for qvel, 2 for action, 1 for friction\n",
    "    d_out = 4 # qpos, qvel\n",
    "    d_hidden = 256\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(d_in, d_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(d_hidden, d_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(d_hidden, d_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(d_hidden, d_out)\n",
    "    )\n",
    "    \n",
    "    lr = 1e-3\n",
    "    batch_size = 64\n",
    "    n_iters = 6000\n",
    "    print_iter = 50\n",
    "    device = 'cuda'\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        batch = train_buffer.get_batch(batch_size)\n",
    "        x, y, x_prev, friction = batch_buffer_to_pred_torch(batch)\n",
    "        if include_friction:\n",
    "            x = torch.cat([x, friction], dim=1)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_prev = x_prev.to(device)\n",
    "        optim.zero_grad()\n",
    "        y_hat = x_prev + model(x)\n",
    "\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if i % print_iter == 0:\n",
    "            val_batch = val_buffer.get_batch(128)\n",
    "            x_val, y_val, x_prev_val, fric_val = batch_buffer_to_pred_torch(val_batch)\n",
    "            if include_friction:\n",
    "                x_val = torch.cat([x_val, fric_val], dim=1)\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            x_prev_val = x_prev_val.to(device)\n",
    "            y_hat_val = x_prev_val + model(x_val)\n",
    "            val_loss = F.mse_loss(y_hat_val, y_val)\n",
    "            print(i, loss.item(), val_loss.item())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.005612609442323446 0.0019001023611053824\n",
      "50 0.0003082512994296849 0.00023471939493902028\n",
      "100 0.0002265569637529552 0.00016066402895376086\n",
      "150 0.0003321518306620419 0.00022417775471694767\n",
      "200 0.00018423606525175273 0.00022708275355398655\n",
      "250 0.00022153067402541637 0.00023813624284230173\n",
      "300 0.00017115396622102708 0.00018756510689854622\n",
      "350 0.000176668370841071 0.00020773083087988198\n",
      "400 0.00022416323190554976 0.00021662807557731867\n",
      "450 0.00026084529235959053 0.00023394257004838437\n",
      "500 0.00022215713397599757 0.0001468068512622267\n",
      "550 0.00019189860904589295 0.00022631704632658511\n",
      "600 0.0001440146006643772 0.00019876024452969432\n",
      "650 0.0003493807162158191 0.0002451499458402395\n",
      "700 0.00018401470151729882 0.00020660311565734446\n",
      "750 0.00013711294741369784 0.0002692607813514769\n",
      "800 0.0001636888482607901 0.0001646681921556592\n",
      "850 0.00024098370340652764 0.0001810419635148719\n",
      "900 0.00020022479293402284 0.0002488477330189198\n",
      "950 0.00019497897301334888 0.00020818927441723645\n",
      "1000 0.0002295061422046274 0.0001978639338631183\n",
      "1050 0.00022610669839195907 0.00022841658210381866\n",
      "1100 0.0001992007892113179 0.00017277499136980623\n",
      "1150 0.0001461756182834506 0.00018925286713056266\n",
      "1200 0.0002813925966620445 0.00020696528372354805\n",
      "1250 0.00024325621780008078 0.00018522143363952637\n",
      "1300 0.00014177599223330617 0.0002554815146140754\n",
      "1350 0.00022505952802021056 0.0001845966326072812\n",
      "1400 0.0002464544086251408 0.00026836752658709884\n",
      "1450 0.00033420464023947716 0.0002967027248814702\n",
      "1500 0.00017461746756453067 0.0002821550879161805\n",
      "1550 0.00017837007180787623 0.00017319324251729995\n",
      "1600 0.00034147530095651746 0.00016854307614266872\n",
      "1650 0.0001757375430315733 0.00018697055929806083\n",
      "1700 0.00033623186754994094 0.00022768907365389168\n",
      "1750 0.00021252932492643595 0.00024311548622790724\n",
      "1800 0.0001962812093552202 0.00023613381199538708\n",
      "1850 0.0002412020694464445 0.00022965089010540396\n",
      "1900 0.00021905533503741026 0.00022361398441717029\n",
      "1950 0.0003430970828048885 0.00019307874026708305\n",
      "2000 0.00018820994591806084 0.0002032904012594372\n",
      "2050 0.000121110919280909 0.00023113354109227657\n",
      "2100 0.00014909157471265644 0.00020730160758830607\n",
      "2150 0.0002042486157733947 0.00020058153313584626\n",
      "2200 0.00019982134108431637 0.00023107207380235195\n",
      "2250 0.0003019285504706204 0.0001441065251128748\n",
      "2300 0.00028186009149067104 0.00018114125123247504\n",
      "2350 0.00019823468755930662 0.0002215639251517132\n",
      "2400 0.0002969031047541648 0.00020634831162169576\n",
      "2450 0.00019100203644484282 0.0001955533807631582\n",
      "2500 0.00014245757483877242 0.00022112243459559977\n",
      "2550 0.00023454413167200983 0.0001593806518940255\n",
      "2600 0.00021088084031362087 0.00027198874158784747\n",
      "2650 0.00016645951836835593 0.00020120409317314625\n",
      "2700 0.00010355954873375595 0.00019903865177184343\n",
      "2750 0.00025165214901790023 0.00021064479369670153\n",
      "2800 0.0001907545083668083 0.00017775714513845742\n",
      "2850 0.0001379980967612937 0.00021075345284771174\n",
      "2900 0.0001828153763199225 0.00018098833970725536\n",
      "2950 0.00017102433776017278 0.00015774361963849515\n",
      "3000 0.00021180576004553586 0.00019581997185014188\n",
      "3050 0.00022084037482272834 0.0002367663400946185\n",
      "3100 0.00026136619271710515 0.00019836440333165228\n",
      "3150 0.00016676101949997246 0.0001979842927539721\n",
      "3200 0.00035248647327534854 0.00023115755175240338\n",
      "3250 0.00020087820303160697 0.00025166996056213975\n",
      "3300 0.0001775984710548073 0.0002127280895365402\n",
      "3350 0.00026030585286207497 0.00023332568525802344\n",
      "3400 0.00017388450214639306 0.00028679578099399805\n",
      "3450 0.0003488612128421664 0.00021298043429851532\n",
      "3500 0.00022832820832263678 0.0002184536715503782\n",
      "3550 0.0001367670192848891 0.00024907325860112906\n",
      "3600 0.00021009778720326722 0.00025013714912347496\n",
      "3650 0.00020835775649175048 0.00019660410180222243\n",
      "3700 0.0001799293386284262 0.00021996076975483447\n",
      "3750 0.000194264852325432 0.00017310782277490944\n",
      "3800 0.00016595199122093618 0.0001996086211875081\n",
      "3850 0.00031522216158919036 0.0002894627978093922\n",
      "3900 0.0001196240191347897 0.00022290342894848436\n",
      "3950 0.00020771357230842113 0.00021506893972400576\n",
      "4000 0.0001621361734578386 0.00016169493028428406\n",
      "4050 0.00015757475921418518 0.0001624708966119215\n",
      "4100 0.000220843794522807 0.0002086869499180466\n",
      "4150 0.0002234333223896101 0.00027484033489599824\n",
      "4200 0.00013848350499756634 0.00019111507572233677\n",
      "4250 0.0002315111632924527 0.0001798824087018147\n",
      "4300 0.00022001539764460176 0.0001705471077002585\n",
      "4350 0.00018273689784109592 0.00017460693197790533\n",
      "4400 9.345014404971153e-05 0.00018043519230559468\n",
      "4450 0.00021291064331308007 0.000249827018706128\n",
      "4500 0.00020922783005516976 0.00018308963626623154\n",
      "4550 0.00036742640077136457 0.00017680160817690194\n",
      "4600 0.00016038041212596 0.0002349733404116705\n",
      "4650 0.00017278993618674576 0.0002406692219665274\n",
      "4700 0.00024674079031683505 0.00020661369489971548\n",
      "4750 0.00031498970929533243 0.00021165405632928014\n",
      "4800 0.00013846110960002989 0.00013417394075077027\n",
      "4850 0.00014784582890570164 0.00021622100030072033\n",
      "4900 0.00023413248709402978 0.00017945040599443018\n",
      "4950 0.0001393838319927454 0.00025078037288039923\n",
      "5000 0.00023411927395500243 0.0003562035271897912\n",
      "5050 0.00016814735135994852 0.00027060959837399423\n",
      "5100 0.00021783012198284268 0.0002506673918105662\n",
      "5150 0.000245344708673656 0.000261891633272171\n",
      "5200 0.00019837490981444716 0.00028183130780234933\n",
      "5250 0.0002056872472167015 0.00016323321324307472\n",
      "5300 0.00017554854275658727 0.00015204507508315146\n",
      "5350 0.00021335636847652495 0.000144239587825723\n",
      "5400 0.00020258646691218019 0.00027686424436978996\n",
      "5450 0.00016915553715080023 0.0001967748539755121\n",
      "5500 0.0001956620835699141 0.00019970498397015035\n",
      "5550 0.00021882340661250055 0.0002567968040239066\n",
      "5600 0.00019626840366981924 0.00020918226800858974\n",
      "5650 0.00015374070790130645 0.00014811457367613912\n",
      "5700 0.00019656805670820177 0.00017442108946852386\n",
      "5750 0.00014636976993642747 0.00018392680794931948\n",
      "5800 0.00023044449335429817 0.00017128745093941689\n",
      "5850 0.00019098297343589365 0.0002577344130259007\n",
      "5900 0.00018064130563288927 0.00022838670702185482\n",
      "5950 0.00024569666129536927 0.00016060446796473116\n",
      "0 0.0009194985032081604 0.003045071382075548\n",
      "50 0.0002856664650607854 0.000220465924940072\n",
      "100 0.00031016411958262324 0.00018295960035175085\n",
      "150 0.00024986962671391666 0.00020633809617720544\n",
      "200 0.00018457832629792392 0.0002021664404310286\n",
      "250 0.000307280890410766 0.00023411826987285167\n",
      "300 0.00020244211191311479 0.00018754357006400824\n",
      "350 0.000338485260726884 0.00013789726654067636\n",
      "400 0.0004256554238963872 0.00029251130763441324\n",
      "450 0.0001927593839354813 0.0002013170305872336\n",
      "500 0.00033028877805918455 0.00017041403043549508\n",
      "550 0.00020122589194215834 0.00023230715305544436\n",
      "600 0.000295499456115067 0.0001638732646824792\n",
      "650 0.00024322610988747329 0.00022085232194513083\n",
      "700 0.0002874817291740328 0.0002524819574318826\n",
      "750 0.00020206242334097624 0.00021409449982456863\n",
      "800 0.00030989537481218576 0.0002749080886133015\n",
      "850 0.0002206731151090935 0.00019488646648824215\n",
      "900 0.0003003544989041984 0.00020075363863725215\n",
      "950 0.00017695187125355005 0.0002612228272482753\n",
      "1000 0.00030677413451485336 0.00016211767797358334\n",
      "1050 0.00030067318584769964 0.00021638412727043033\n",
      "1100 0.0002052765485132113 0.0002301508648088202\n",
      "1150 0.00024337440845556557 0.00018328159058000892\n",
      "1200 0.0003008818021044135 0.0003172336728312075\n",
      "1250 0.00045512703945860267 0.00013971295265946537\n",
      "1300 0.0002582465822342783 0.00023689900990575552\n",
      "1350 0.00016743317246437073 0.00019414702546782792\n",
      "1400 0.0002544816234149039 0.0002192685496993363\n",
      "1450 0.00020792549184989184 0.00016074394807219505\n",
      "1500 0.0001813073904486373 0.00016994307225104421\n",
      "1550 0.00017323638894595206 0.0002131989604094997\n",
      "1600 0.00019143577083013952 0.00023018963111098856\n",
      "1650 0.00016857346054166555 0.00024890602799132466\n",
      "1700 0.00011311097478028387 0.0002811566519085318\n",
      "1750 0.0001624524884391576 0.00022393581457436085\n",
      "1800 0.00018630900012794882 0.00020972927450202405\n",
      "1850 0.0001288128551095724 0.00017285400826949626\n",
      "1900 0.0001900731585919857 0.00024308987485710531\n",
      "1950 0.00018303687102161348 0.0002114822855219245\n",
      "2000 0.00015276696649380028 0.0002010673051699996\n",
      "2050 0.0002037045924225822 0.00018767689471133053\n",
      "2100 0.00022422068286687136 0.0003121270565316081\n",
      "2150 0.00018374717910774052 0.00019012854318134487\n",
      "2200 0.00018219123012386262 0.0002463500131852925\n",
      "2250 0.00018959969747811556 0.00023401308862958103\n",
      "2300 0.00020381981448736042 0.0001492334413342178\n",
      "2350 0.00014573396765626967 0.0002140372816938907\n",
      "2400 0.0002827757562045008 0.00022758118575438857\n",
      "2450 0.0001761384919518605 0.00024393928470090032\n",
      "2500 0.00028533581644296646 0.00019479834008961916\n",
      "2550 0.00020333155407570302 0.00017901032697409391\n",
      "2600 0.00027574284467846155 0.0002197826688643545\n",
      "2650 0.0001749036309774965 0.000176122339325957\n",
      "2700 0.00020774314180016518 0.00022423057816922665\n",
      "2750 0.00025154498871415854 0.0001730649673845619\n",
      "2800 0.00013675492664333433 0.00020072542247362435\n",
      "2850 0.00023199027054943144 0.00021264003589749336\n",
      "2900 0.0001884890953078866 0.00021355999342631549\n",
      "2950 0.0002924505970440805 0.00022263922437559813\n",
      "3000 0.00016522131045348942 0.00021299556829035282\n",
      "3050 0.00017293122073169798 0.00020233738177921623\n",
      "3100 0.000146487305755727 0.0002447175211273134\n",
      "3150 0.00025865601492114365 0.0002003355184569955\n",
      "3200 0.0002491086779627949 0.0002294705482199788\n",
      "3250 0.00021843310969416052 0.00025147158885374665\n",
      "3300 0.0002308479743078351 0.00018158796592615545\n",
      "3350 0.000153995948494412 0.00020968730677850544\n",
      "3400 0.00012981981853954494 0.00015098137373570353\n",
      "3450 0.00018921356240753084 0.00013729557394981384\n",
      "3500 0.00019010652613360435 0.00018794662901200354\n",
      "3550 0.00023827736731618643 0.00019620027160272002\n",
      "3600 0.0003586629463825375 0.00023666667402721941\n",
      "3650 0.00018035480752587318 0.0002155722031602636\n",
      "3700 0.00013731322542298585 0.0001334131957264617\n",
      "3750 0.0002102177677443251 0.00020065830904059112\n",
      "3800 0.0002770568535197526 0.00019566199625842273\n",
      "3850 0.0001805409847293049 0.00021711400768253952\n",
      "3900 0.0002485128352418542 0.0002502932329662144\n",
      "3950 0.0001392076228512451 0.00020356442837510258\n",
      "4000 0.00016634006169624627 0.00020264579507056624\n",
      "4050 0.00019376230193302035 0.0003311682667117566\n",
      "4100 0.00015269388677552342 0.0001931467850226909\n",
      "4150 0.00021017517428845167 0.000152902357513085\n",
      "4200 0.00020235453848727047 0.00024084057076834142\n",
      "4250 0.00021032409858889878 0.0002090813359245658\n",
      "4300 0.00024611823027953506 0.0001817292650230229\n",
      "4350 0.00020504114218056202 0.0001850888947956264\n",
      "4400 0.00011750807607313618 0.0001833332353271544\n",
      "4450 0.00014030348393134773 0.00019731675274670124\n",
      "4500 0.0002395228366367519 0.00020992396457586437\n",
      "4550 0.00022835418349131942 0.00021811240003444254\n",
      "4600 0.00025911128614097834 0.0002487656020093709\n",
      "4650 0.00015386397717520595 0.0001896660542115569\n",
      "4700 0.00018017730326391757 0.00018239016935694963\n",
      "4750 0.0001581798424012959 0.00015814564540050924\n",
      "4800 0.00021923831081949174 0.0002625345659907907\n",
      "4850 0.00022517979959957302 0.0001944751275004819\n",
      "4900 0.00015542971959803253 0.0001361434842692688\n",
      "4950 0.00012574519496411085 0.00019690104818437248\n",
      "5000 0.0001935613836394623 0.0001947449636645615\n",
      "5050 0.00021971817477606237 0.00022039352916181087\n",
      "5100 0.000127689098007977 0.0001688980992184952\n",
      "5150 0.00015168581739999354 0.00020599222625605762\n",
      "5200 0.00019928993424400687 0.00019454333232715726\n",
      "5250 0.00016492127906531096 0.0002006677386816591\n",
      "5300 0.00019097363110631704 0.00020571320783346891\n",
      "5350 0.0001224114530486986 0.00015389733016490936\n",
      "5400 0.00019613260519690812 0.00013120201765559614\n",
      "5450 0.00012369564501568675 0.00021341477986425161\n",
      "5500 0.0002255612489534542 0.00020197434059809893\n",
      "5550 0.00016514980234205723 0.00021006495808251202\n",
      "5600 0.0001533317263238132 0.0001962729002116248\n",
      "5650 0.00016789493383839726 0.0001817128504626453\n",
      "5700 0.00023726742074359208 0.0002405270643066615\n",
      "5750 0.00023043554392643273 0.00017326229135505855\n",
      "5800 0.00017886108253151178 0.00016473678988404572\n",
      "5850 0.00026461968082003295 0.00017123637371696532\n",
      "5900 0.00016102605150081217 0.000249189994065091\n",
      "5950 0.00011537282989593223 0.00017229633522219956\n"
     ]
    }
   ],
   "source": [
    "pred_model_gt = train_pred_model(train_buffer, val_buffer)\n",
    "pred_model_no_fric = train_pred_model(train_buffer, val_buffer, include_friction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_osi_pred(osi_model, pred_model, buffer, h, val_size=5000):\n",
    "    batch = buffer.get_traj_batch(val_size, h)\n",
    "    x_hist, gt_fric = buffer_to_osi_torch(batch)\n",
    "    x, y, x_prev, gt_fric = traj_buffer_to_pred_torch(batch)\n",
    "    \n",
    "    x_hist = x_hist.to(device)\n",
    "    gt_fric = gt_fric.to(device)\n",
    "    x = x.to(device)\n",
    "    x_prev = x_prev.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    estimated_fric = osi_model(x_hist)\n",
    "    x = torch.cat([x, estimated_fric], dim=1)\n",
    "    \n",
    "    y_hat = x_prev + pred_model(x)\n",
    "    \n",
    "    pos_mse = F.mse_loss(y_hat, y)\n",
    "    fric_mse = F.mse_loss(estimated_fric, gt_fric)\n",
    "    return pos_mse.item(), fric_mse.item()\n",
    "\n",
    "def eval_pred_gt(pred_model, buffer, val_size=5000, include_friction=True):\n",
    "    batch = buffer.get_batch(val_size)\n",
    "    x, y, x_prev, gt_fric = batch_buffer_to_pred_torch(batch)\n",
    "    \n",
    "    gt_fric = gt_fric.to(device)\n",
    "    x = x.to(device)\n",
    "    x_prev = x_prev.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    if include_friction:\n",
    "        x = torch.cat([x, gt_fric], dim=1)\n",
    "    \n",
    "    y_hat = x_prev + pred_model(x)\n",
    "    \n",
    "    pos_mse = F.mse_loss(y_hat, y)\n",
    "    return pos_mse.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00019378271827008575 0.0001789461966836825 0.00017983032739721239\n"
     ]
    }
   ],
   "source": [
    "pos_mse_osi, fric_mse = eval_osi_pred(osi_model, pred_model_gt, val_buffer, h)\n",
    "pos_gt_mse = eval_pred_gt(pred_model_gt, val_buffer)\n",
    "pos_no_fric_mse = eval_pred_gt(pred_model_no_fric, val_buffer, include_friction=False)\n",
    "\n",
    "print(pos_mse_osi, pos_gt_mse, pos_no_fric_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

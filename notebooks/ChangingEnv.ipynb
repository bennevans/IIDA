{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from varyingsim.box import BoxEnv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buf_size, buf_shapes):\n",
    "        self.buf_size = buf_size\n",
    "        self.cur_buf_size = 0\n",
    "        self.cur_buf_idx = 0\n",
    "\n",
    "        self.buffers = []\n",
    "        for shape in buf_shapes:\n",
    "            self.buffers.append(np.zeros((buf_size, *shape)))\n",
    "\n",
    "    def add_to_buffer(self, data):\n",
    "        for datum, buffer in zip(data, self.buffers):\n",
    "            buffer[self.cur_buf_idx] = datum\n",
    "\n",
    "        if self.cur_buf_size < self.buf_size:\n",
    "            self.cur_buf_size += 1\n",
    "        self.cur_buf_idx = (self.cur_buf_idx + 1) % self.buf_size\n",
    "\n",
    "    def get_buffers(self):\n",
    "        return self.buffers\n",
    "\n",
    "    def _get_batch_range(self, start, stop, batch_size):\n",
    "        rand_idxs = np.random.choice(np.arange(start, stop), batch_size)\n",
    "        ret = []\n",
    "        for buffer in self.buffers:\n",
    "            ret.append(buffer[rand_idxs])\n",
    "        return ret\n",
    "    \n",
    "    def get_batch(self, batch_size):\n",
    "        return self._get_batch_range(0, self.cur_buf_size, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.cur_buf_size\n",
    "    \n",
    "    def reset(self):\n",
    "        self.cur_buf_size = 0\n",
    "        self.cur_buf_idx = 0\n",
    "\n",
    "class ContinualSplitBuffer:\n",
    "    def __init__(self, buf_size, buf_shapes, train_val_ratio):\n",
    "        self.train_val_ratio = train_val_ratio\n",
    "        train_size = int(buf_size * train_val_ratio)\n",
    "        self.train_buf = Buffer(train_size , buf_shapes)\n",
    "        self.val_buf = Buffer(buf_size - train_size, buf_shapes)\n",
    "        \n",
    "    @property\n",
    "    def val_idx(self):\n",
    "        return int(self.cur_buf_size * self.train_val_ratio)\n",
    "    \n",
    "    \n",
    "    def add_to_buffer(self, data):\n",
    "        if np.random.rand() < self.train_val_ratio:\n",
    "            self.train_buf.add_to_buffer(data)\n",
    "        else:\n",
    "            self.val_buf.add_to_buffer(data)\n",
    "    \n",
    "    def get_train_batch(self, batch_size):\n",
    "        return self.train_buf.get_batch(batch_size)\n",
    "    \n",
    "    def get_val_batch(self, batch_size):\n",
    "        return self.val_buf.get_batch(batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.val_buf) + len(self.train_buf)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val_buf.reset()\n",
    "        self.train_buf.reset()\n",
    "    \n",
    "#     def get_train_batch(self, batch_size):\n",
    "#         return self._get_batch_range(0, self.val_idx, batch_size)\n",
    "    \n",
    "#     def get_val_batch(self, batch_size):\n",
    "#         return self._get_batch_range(self.val_idx, self.cur_buf_size, batch_size)\n",
    "    \n",
    "    \n",
    "class Learn():\n",
    "\n",
    "    def __init__(self, model, optim, loss_fn):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.loss_fn = loss_fn\n",
    "        self.losses = []\n",
    "        self.frictions = []\n",
    "    \n",
    "    def learn(self, batch, include_friction):\n",
    "        xy = torch.from_numpy(batch[0]).float()\n",
    "        xy_prev = torch.from_numpy(batch[1]).float()\n",
    "        xy_vel = torch.from_numpy(batch[2]).float()\n",
    "        xy_vel_prev = torch.from_numpy(batch[3]).float()\n",
    "        act = torch.from_numpy(batch[4]).float()\n",
    "        friction = torch.from_numpy(batch[5]).float()\n",
    "\n",
    "        pos_prev = torch.cat([xy_prev, xy_vel_prev], dim=1)\n",
    "        features = torch.cat([xy_prev, xy_vel_prev, act] + ([friction] if include_friction else []) , dim=1)\n",
    "        labels = torch.cat([xy, xy_vel], dim=1)\n",
    "\n",
    "        self.optim.zero_grad()\n",
    "        y_hat = pos_prev + self.model(features)\n",
    "        loss = self.loss_fn(y_hat, labels)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.item()\n",
    "\n",
    "def process(buffer, learner, env, prev_obs, obs, a, t, include_friction):\n",
    "    xy_prev = prev_obs[0:2]\n",
    "    xy = obs[0:2]\n",
    "    xy_vel_prev = prev_obs[3:5]\n",
    "    xy_vel = obs[3:5]\n",
    "    friction = env.get_floor_friction()\n",
    "    learner.frictions.append(friction)\n",
    "\n",
    "\n",
    "    buffer.add_to_buffer([xy, xy_prev, xy_vel, xy_vel_prev, a] + ([friction] if include_friction else []))\n",
    "    learn_freq = 16\n",
    "    batch_size = 64\n",
    "\n",
    "    if t % learn_freq == 0:\n",
    "        batch = buffer.get_batch(batch_size)\n",
    "        loss = learner.learn(batch, include_friction)\n",
    "        learner.losses.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_mass_step(env, t):\n",
    "    if t // 2000 % 2 == 0:\n",
    "        env.set_mass(8.0)\n",
    "    else:\n",
    "        env.set_mass(1.0)\n",
    "        \n",
    "def set_mass_step(env, t):\n",
    "    env.set_mass(8.0)\n",
    "\n",
    "def set_friction_sin(env, t, scale=213):\n",
    "    env.set_floor_friction(np.sin(t / scale) * 0.15 + 1.15)\n",
    "    \n",
    "def set_friction_step(env, t):\n",
    "    if t // 123 % 2 == 0:\n",
    "        env.set_floor_friction(1.0)\n",
    "    else:\n",
    "        env.set_floor_friction(1.3)\n",
    "\n",
    "def set_friction_rand(env, t):\n",
    "    fric_range = [0.8, 1.4]\n",
    "    fric_change_prob = 0.05\n",
    "    if np.random.rand() < fric_change_prob:\n",
    "        env.set_floor_friction(np.random.uniform(fric_range[0], fric_range[1]))\n",
    "\n",
    "def set_nothing(env, t):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_fn = set_friction_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [(2,)] * 5 + [(1,)]\n",
    "T = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model(d_in, d_out, d_hidden, nonlin = nn.ReLU):\n",
    "    return nn.Sequential(\n",
    "    nn.Linear(d_in, d_hidden),\n",
    "    nonlin(),\n",
    "    nn.Linear(d_hidden, d_hidden),\n",
    "    nonlin(),\n",
    "    nn.Linear(d_hidden, d_hidden),\n",
    "    nonlin(),\n",
    "    nn.Linear(d_hidden, d_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(set_param_fn, buf_size, include_friction):\n",
    "    \n",
    "    d_in = 6 + include_friction\n",
    "    d_out = 4\n",
    "    d_hidden = 256\n",
    "    lr = 1e-4\n",
    "    nonlin = nn.ReLU\n",
    "    \n",
    "    buffer = Buffer(buf_size, shapes)\n",
    "    env = BoxEnv(set_param_fn=set_param_fn)\n",
    "\n",
    "    model = new_model(d_in, d_out, d_hidden, nonlin)\n",
    "\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    learner = Learn(model, optim, F.mse_loss)\n",
    "\n",
    "    obs = env.reset()\n",
    "    t = 0\n",
    "    scale = 100\n",
    "    \n",
    "    qpos = []\n",
    "    qvel = []\n",
    "    actions = []\n",
    "    frictions = []\n",
    "    \n",
    "    while t < T:\n",
    "        a = [np.sin(t / scale), np.cos(t / scale)]\n",
    "        prev_obs = obs\n",
    "        qpos.append(env.sim.data.qpos.copy())\n",
    "        qvel.append(env.sim.data.qvel.copy())\n",
    "        actions.append(a)\n",
    "        obs, rew, done, info = env.step(a)\n",
    "        frictions.append(env.get_floor_friction())\n",
    "\n",
    "        process(buffer, learner, env, prev_obs, obs, a, t, include_friction)\n",
    "        t += 1\n",
    "    \n",
    "    return learner, buffer, {'qpos': qpos, 'qvel': qvel, 'actions': actions, 'frictions': frictions}\n",
    "\n",
    "def generate_data(set_param_fn, T_start, H):\n",
    "    env = BoxEnv(set_param_fn=set_param_fn)\n",
    "\n",
    "    obs = env.reset()\n",
    "    t = 0\n",
    "    scale = 100\n",
    "    \n",
    "    qpos = []\n",
    "    qvel = []\n",
    "    actions = []\n",
    "    frictions = []\n",
    "    \n",
    "    while t < T_start + H:\n",
    "        a = [np.sin(t / scale), np.cos(t / scale)]\n",
    "        \n",
    "        if t >= T_start:\n",
    "            prev_obs = obs\n",
    "            qpos.append(env.sim.data.qpos.copy())\n",
    "            qvel.append(env.sim.data.qvel.copy())\n",
    "            actions.append(a)\n",
    "            obs, rew, done, info = env.step(a)\n",
    "            frictions.append(env.get_floor_friction())\n",
    "        t += 1\n",
    "    \n",
    "    return {'qpos': qpos, 'qvel': qvel, 'actions': actions, 'frictions': frictions}\n",
    "\n",
    "def fill_buffer(set_param_fn, buf_size, include_friction):\n",
    "    env = BoxEnv(set_param_fn=set_param_fn)\n",
    "    buffer = ContinualSplitBuffer(buf_size, shapes, 0.9)\n",
    "    obs = env.reset()\n",
    "    t = 0\n",
    "    scale = 100\n",
    "    \n",
    "    while t < buf_size:\n",
    "        a = [np.sin(t / scale), np.cos(t / scale)]\n",
    "        \n",
    "        prev_obs = obs\n",
    "        obs, rew, done, info = env.step(a)\n",
    "\n",
    "        xy_prev = prev_obs[0:2]\n",
    "        xy = obs[0:2]\n",
    "        xy_vel_prev = prev_obs[3:5]\n",
    "        xy_vel = obs[3:5]\n",
    "        friction = env.get_floor_friction()\n",
    "        buffer.add_to_buffer([xy, xy_prev, xy_vel, xy_vel_prev, a] + ([friction] if include_friction else []))\n",
    "            \n",
    "        t += 1\n",
    "    \n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_buff_losses = learner.losses\n",
    "large_include_learner, learner_buffer, states = run_exp(param_fn, T, True)\n",
    "large_buff_losses = large_include_learner.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_buff_losses = learner.losses\n",
    "small_include_learner, _, _ = run_exp(param_fn, 256, True)\n",
    "small_buff_losses = small_include_learner.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_no_include = learner.losses\n",
    "large_no_include_learner, _, _ = run_exp(param_fn, T, False)\n",
    "large_no_include = large_no_include_learner.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_no_include_learner, _, _ = run_exp(param_fn, 256, False)\n",
    "small_no_include = small_no_include_learner.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ef512b6a3b44269a76a4fe74453f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "start_iter = 25\n",
    "xs = np.arange(len(small_buff_losses))[start_iter:] * 16\n",
    "\n",
    "frics_scaled = np.array(small_no_include_learner.frictions[::16][start_iter:]) / 1000\n",
    "\n",
    "plt.plot(xs, small_buff_losses[start_iter:], label='small buff')\n",
    "plt.plot(xs, large_buff_losses[start_iter:], label='large buff')\n",
    "plt.plot(xs, large_no_include[start_iter:], label='large buff no fric')\n",
    "# plt.plot(xs, small_no_include[start_iter:], label='small buff no fric')\n",
    "plt.plot(xs, frics_scaled, label='friction')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train i.i.d. model on the data we've seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_friction = True\n",
    "buffer = learner_buffer\n",
    "\n",
    "def train_iid_model(include_friction):\n",
    "    d_in = 6 + include_friction\n",
    "    d_out = 4\n",
    "    d_hidden = 256\n",
    "    lr = 1e-3\n",
    "    model = new_model(d_in, d_out, d_hidden)\n",
    "    lr = 1e-3\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    learner = Learn(model, optim, F.mse_loss)\n",
    "    batch_size = 64\n",
    "    num_epochs = 1\n",
    "    \n",
    "    sl_losses = []\n",
    "    for i in range(0, T * num_epochs, 16):\n",
    "        batch = buffer.get_batch(batch_size)\n",
    "        loss = learner.learn(batch, include_friction)\n",
    "    #     print(i, loss)\n",
    "        sl_losses.append(loss)\n",
    "    return model, sl_losses\n",
    "\n",
    "model_iid_no_fric, no_fric_losses = train_iid_model(False)\n",
    "model_iid_fric, fric_losses = train_iid_model(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563d5addd9f4471da57f680c839a9167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "start_iter = 500\n",
    "xs = np.arange(len(small_buff_losses))[start_iter:] * 16\n",
    "frics_scaled = np.array(small_no_include_learner.frictions[::16][start_iter:]) / 1000\n",
    "sl_losses = fric_losses if include_friction else no_fric_losses\n",
    "xs_sl = np.arange(len(sl_losses))[start_iter:] * 16\n",
    "\n",
    "# plt.plot(xs, small_buff_losses[start_iter:], label='small buff')\n",
    "plt.plot(xs_sl, sl_losses[start_iter:], label='SL')\n",
    "# plt.plot(xs, large_no_include[start_iter:], label='large buff no fric')\n",
    "plt.plot(xs, small_no_include[start_iter:], label='small buff no fric')\n",
    "plt.plot(xs, frics_scaled, label='friction')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(large_no_include_learner.frictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_batch(qpos, qvel, act, friction=None):\n",
    "    xy = qpos[0:2]\n",
    "    xy_vel = qvel[0:2]\n",
    "    if friction:\n",
    "        return np.concatenate([xy, xy_vel, act, friction])\n",
    "    else:\n",
    "        return np.concatenate([xy, xy_vel, act])\n",
    "    \n",
    "def state_to_xy_vel(qpos, qvel):\n",
    "    xy = qpos[0:2]\n",
    "    xy_vel = qvel[0:2]\n",
    "    return np.concatenate([xy, xy_vel])\n",
    "\n",
    "def obs_to_xy_vel(obs):\n",
    "    xy = obs[0:2]\n",
    "    xy_vel = obs[3:5]\n",
    "    return xy, xy_vel\n",
    "\n",
    "def torch_to_xy_vel(output):\n",
    "    xy = output[0:2]\n",
    "    xy_vel = output[2:4]\n",
    "    return xy, xy_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_model_single(model, include_friction, qpos, qvel, actions, frictions):\n",
    "    idx = 0\n",
    "    def set_param_fn(env, t):\n",
    "        env.set_floor_friction(frictions[idx])\n",
    "    env = BoxEnv(set_param_fn=set_param_fn)\n",
    "    \n",
    "    sim_states_prime = []\n",
    "    model_states_prime = []\n",
    "    for fric, act in zip(frictions, actions):\n",
    "        env.set_state(qpos[idx], qvel[idx])\n",
    "        obs, rew, done, info = env.step(actions[idx])\n",
    "        sim_states_prime.append(obs_to_xy_vel(obs))\n",
    "        \n",
    "        model_state = state_to_batch(qpos[idx], qvel[idx], act, friction=[fric] if include_friction else None)\n",
    "\n",
    "        model_torch = torch.from_numpy(model_state).float()\n",
    "        offset = model(model_torch)\n",
    "        model_pred = state_to_xy_vel(qpos[idx], qvel[idx]) + offset.detach().numpy()\n",
    "        model_states_prime.append(torch_to_xy_vel(model_pred))\n",
    "        \n",
    "        idx += 1\n",
    "    return sim_states_prime, model_states_prime\n",
    "\n",
    "def rollout_model(model, include_friction, init_qpos, init_qvel, actions, frictions):\n",
    "    idx = 0\n",
    "    def set_param_fn(env, t):\n",
    "        env.set_floor_friction(frictions[idx])\n",
    "    env = BoxEnv(set_param_fn=set_param_fn)\n",
    "    env.set_state(init_qpos, init_qvel)\n",
    "\n",
    "    sim_states_prime = []\n",
    "    \n",
    "    for fric, act in zip(frictions, actions):\n",
    "        obs, rew, done, info = env.step(actions[idx])\n",
    "        sim_states_prime.append(obs_to_xy_vel(obs))\n",
    "        idx += 1\n",
    "        \n",
    "    model_states_prime = []\n",
    "    \n",
    "    model_state = torch.cat([torch.from_numpy(init_qpos)[:2], torch.from_numpy(init_qvel)[:2]]).float()\n",
    "    for fric, act in zip(frictions, actions):\n",
    "        if not include_friction:\n",
    "            model_input = torch.cat([model_state, torch.tensor(act).float()])\n",
    "        else:\n",
    "            model_input = torch.cat([model_state, torch.tensor(act).float(), torch.tensor([fric]).float()])\n",
    "\n",
    "        offset = model(model_input)\n",
    "        model_pred = model_state[:4] + offset\n",
    "        xy, xy_vel = torch_to_xy_vel(model_pred)\n",
    "        model_states_prime.append((xy.detach().numpy(), xy_vel.detach().numpy()))\n",
    "        model_state = model_pred.detach().clone()\n",
    "        \n",
    "    return sim_states_prime, model_states_prime\n",
    "\n",
    "def vis_rollouts2(rollout1, rollout2, vscale=1000, c1='r', c2='b'):\n",
    "    plt.scatter(rollout1[:,0, 0], rollout1[:,0, 1], marker='.', color=c1)\n",
    "    plt.scatter(rollout2[:,0, 0], rollout2[:,0, 1], marker='.', color=c2)\n",
    "    \n",
    "    for x, y, vx, vy in zip(rollout1[:,0, 0], rollout1[:,0, 1], rollout1[:,1, 0], rollout1[:,1, 1]):\n",
    "        plt.arrow(x, y, vx / vscale, vy / vscale, width=1e-4, color=c1)\n",
    "        \n",
    "    for x, y, vx, vy in zip(rollout2[:,0, 0], rollout2[:,0, 1], rollout2[:,1, 0], rollout2[:,1, 1]):\n",
    "        plt.arrow(x, y, vx / vscale, vy / vscale, width=1e-4, color=c2)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def vis_rollouts(rollout1, rollout2, rollout3, vscale=1000, c1='r', c2='b', c3='g', labels=['traj1', 'traj2', 'traj3']):\n",
    "    plt.scatter(rollout1[:,0, 0], rollout1[:,0, 1], marker='.', color=c1, label=labels[0])\n",
    "    plt.scatter(rollout2[:,0, 0], rollout2[:,0, 1], marker='.', color=c2, label=labels[1])\n",
    "    plt.scatter(rollout3[:,0, 0], rollout3[:,0, 1], marker='.', color=c3, label=labels[2])\n",
    "    \n",
    "    for x, y, vx, vy in zip(rollout1[:,0, 0], rollout1[:,0, 1], rollout1[:,1, 0], rollout1[:,1, 1]):\n",
    "        plt.arrow(x, y, vx / vscale, vy / vscale, width=1e-4, color=c1)\n",
    "        \n",
    "    for x, y, vx, vy in zip(rollout2[:,0, 0], rollout2[:,0, 1], rollout2[:,1, 0], rollout2[:,1, 1]):\n",
    "        plt.arrow(x, y, vx / vscale, vy / vscale, width=1e-4, color=c2)\n",
    "    \n",
    "    for x, y, vx, vy in zip(rollout3[:,0, 0], rollout3[:,0, 1], rollout3[:,1, 0], rollout3[:,1, 1]):\n",
    "        plt.arrow(x, y, vx / vscale, vy / vscale, width=1e-4, color=c3)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_states_prime, model_states_prime = rollout_model_single(small_no_include_learner.model, False, states['qpos'], states['qvel'], states['actions'], states['frictions'])\n",
    "seq_ssp = np.array(sim_states_prime)\n",
    "seq_msp = np.array(model_states_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_states_prime, model_states_prime = rollout_model_single(model_iid_no_fric, False, states['qpos'], states['qvel'], states['actions'], states['frictions'])\n",
    "iid_ssp = np.array(sim_states_prime)\n",
    "iid_msp = np.array(model_states_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8873a9a0d7f14a5489c4bb81dcf85855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_idx = 800\n",
    "H = 2000\n",
    "%matplotlib widget\n",
    "vis_rollouts(seq_ssp[start_idx:start_idx+H], seq_msp[start_idx:start_idx+H], iid_msp[start_idx:start_idx+H], labels=['sim', 'seq', 'iid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14304274885636736 0.10107963924621712\n"
     ]
    }
   ],
   "source": [
    "test_T_start = T\n",
    "test_H = 3000\n",
    "\n",
    "# learner = small_no_include_learner\n",
    "# learner = large_no_include_learner\n",
    "learner = large_include_learner\n",
    "\n",
    "test_data = generate_data(param_fn, test_T_start, test_H)\n",
    "sim_states_prime, model_states_prime = rollout_model_single(learner.model, True, test_data['qpos'], test_data['qvel'], test_data['actions'], test_data['frictions'])\n",
    "seq_ssp = np.array(sim_states_prime)\n",
    "seq_msp = np.array(model_states_prime)\n",
    "_, model_states_prime = rollout_model_single(model_iid_fric, True, test_data['qpos'], test_data['qvel'], test_data['actions'], test_data['frictions'])\n",
    "iid_msp = np.array(model_states_prime)\n",
    "model_iid_fric\n",
    "seq_x_err = np.average(np.sqrt(np.sum((seq_ssp[:, 0] - seq_msp[:, 0]) **2)))\n",
    "iid_x_err = np.average(np.sqrt(np.sum((seq_ssp[:, 0] - iid_msp[:, 0]) **2)))\n",
    "print(seq_x_err, iid_x_err)\n",
    "# 0.3001861633402057 0.08439425154122533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5267fb90a047c78250eae8ca25ee31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_idx = 0\n",
    "H = test_H\n",
    "%matplotlib widget\n",
    "vis_rollouts(seq_ssp[start_idx:start_idx+H], seq_msp[start_idx:start_idx+H], iid_msp[start_idx:start_idx+H], labels=['sim', 'seq', 'iid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06977142196086375 0.04536650428627988\n"
     ]
    }
   ],
   "source": [
    "test_T_start = T + 23544\n",
    "test_H = 2000\n",
    "\n",
    "# learner = small_no_include_learner\n",
    "# learner = large_no_include_learner\n",
    "learner = large_include_learner\n",
    "\n",
    "trunc_idx = 500\n",
    "\n",
    "test_data = generate_data(param_fn, test_T_start, test_H)\n",
    "sim_states_prime, model_states_prime = rollout_model_single(model_iid_no_fric, False, test_data['qpos'], test_data['qvel'], test_data['actions'], test_data['frictions'])\n",
    "seq_ssp = np.array(sim_states_prime)[trunc_idx:]\n",
    "no_fric_msp = np.array(model_states_prime)[trunc_idx:]\n",
    "_, model_states_prime = rollout_model_single(model_iid_fric, True, test_data['qpos'], test_data['qvel'], test_data['actions'], test_data['frictions'])\n",
    "fric_msp = np.array(model_states_prime)[trunc_idx:]\n",
    "\n",
    "no_fric_x_err = np.average(np.sqrt(np.sum((seq_ssp[:, 0] - no_fric_msp[:, 0]) **2)))\n",
    "fric_x_err = np.average(np.sqrt(np.sum((seq_ssp[:, 0] - fric_msp[:, 0]) **2)))\n",
    "print(no_fric_x_err, fric_x_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05b88b39fb441e19263034c88d98279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_idx = 0\n",
    "H = test_H\n",
    "%matplotlib widget\n",
    "vis_rollouts(seq_ssp[start_idx:start_idx+H], no_fric_msp[start_idx:start_idx+H], fric_msp[start_idx:start_idx+H], labels=['sim', 'no fric', 'fric'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iid with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "buffer = fill_buffer(param_fn, N, True)\n",
    "\n",
    "def train_iid_model_param(buffer, include_friction, d_hidden=256, lr=1e-3, weight_decay=1e-6, batch_size=64, num_iters=10000, valid_interval=2000):\n",
    "    d_in = 6 + include_friction\n",
    "    d_out = 4\n",
    "    model = new_model(d_in, d_out, d_hidden)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    learner = Learn(model, optim, F.mse_loss)\n",
    "    num_epochs = 1\n",
    "    \n",
    "    sl_losses = []\n",
    "    valid_models = []\n",
    "    valid_losses = []\n",
    "    for i in range(0, num_iters):\n",
    "        batch = buffer.get_train_batch(batch_size)\n",
    "        loss = learner.learn(batch, include_friction)\n",
    "        \n",
    "        if i % valid_interval == 0:\n",
    "            valid_batch = buffer.get_val_batch(buffer.val_buf.cur_buf_size)\n",
    "            xy = torch.from_numpy(valid_batch[0]).float()\n",
    "            xy_prev = torch.from_numpy(valid_batch[1]).float()\n",
    "            xy_vel = torch.from_numpy(valid_batch[2]).float()\n",
    "            xy_vel_prev = torch.from_numpy(valid_batch[3]).float()\n",
    "            act = torch.from_numpy(valid_batch[4]).float()\n",
    "            friction = torch.from_numpy(valid_batch[5]).float()\n",
    "\n",
    "            pos_prev = torch.cat([xy_prev, xy_vel_prev], dim=1)\n",
    "            features = torch.cat([xy_prev, xy_vel_prev, act] + ([friction] if include_friction else []) , dim=1)\n",
    "            labels = torch.cat([xy, xy_vel], dim=1)\n",
    "\n",
    "            y_hat = pos_prev + model(features)\n",
    "            valid_loss = F.mse_loss(y_hat, labels)\n",
    "            valid_losses.append(valid_loss.item())\n",
    "            valid_models.append(deepcopy(model))\n",
    "            print(i, loss, valid_loss.item())\n",
    "            \n",
    "        sl_losses.append(loss)\n",
    "    return model, sl_losses, valid_losses, valid_models\n",
    "\n",
    "def train_many_params(buffer, include_friction, params):\n",
    "    best_models = []\n",
    "    models = []\n",
    "    vals = []\n",
    "    infos = []\n",
    "    for param in params:\n",
    "        print(param)\n",
    "        model, sl_losses, valid_losses, valid_models = train_iid_model_param(buffer, include_friction, **param)\n",
    "        best_val_idx = np.argmin(valid_losses)\n",
    "        best_model = valid_models[best_val_idx]\n",
    "        best_models.append(best_model)\n",
    "        models.append(model)\n",
    "        vals.append(valid_losses[best_val_idx])\n",
    "        info = deepcopy(param)\n",
    "        info['stop_idx'] = best_val_idx * info['valid_interval']\n",
    "        infos.append(info)\n",
    "    return models, best_models, vals, infos\n",
    "\n",
    "base_params = dict(d_hidden=256, lr=1e-4, weight_decay=0.0, batch_size=64, num_iters=60000, valid_interval=5000)\n",
    "\n",
    "def run_cv(buffer, include_friction):\n",
    "    params = [base_params]\n",
    "    # lr\n",
    "    lr_1 = deepcopy(base_params)\n",
    "    lr_1['lr'] = 1e-2\n",
    "    params.append(lr_1)\n",
    "    lr_2 = deepcopy(base_params)\n",
    "    lr_2['lr'] = 1e-4\n",
    "    params.append(lr_2)\n",
    "    # wd\n",
    "    wd_1 = deepcopy(base_params)\n",
    "    wd_1['weight_decay'] = 1e-6\n",
    "    params.append(wd_1)\n",
    "    wd_2 = deepcopy(base_params)\n",
    "    wd_2['weight_decay'] = 1e-3\n",
    "    params.append(wd_2)\n",
    "    # batch size\n",
    "    bs_1 = deepcopy(base_params)\n",
    "    bs_1['batch_size'] = 32\n",
    "    params.append(bs_1)\n",
    "    bs_2 = deepcopy(base_params)\n",
    "    bs_2['batch_size'] = 128\n",
    "    params.append(bs_2)\n",
    "    \n",
    "    return train_many_params(buffer, include_friction, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fric_models, fric_best_models, fric_vals, fric_infos = run_cv(buffer, True)\n",
    "# no_fric_models, no_fric_best_models, no_fric_vals, no_fric_infos = run_cv(buffer, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_fric_idx = np.argmin(fric_vals)\n",
    "# best_no_fric_idx = np.argmin(no_fric_vals)\n",
    "# best_fric_model = fric_models[best_fric_idx]\n",
    "# best_no_fric_model = no_fric_models[best_no_fric_idx]\n",
    "# print(fric_vals[best_fric_idx], no_fric_vals[best_no_fric_idx])\n",
    "# print('best fric', fric_infos[best_fric_idx])\n",
    "# print('best no fric', no_fric_infos[best_no_fric_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For quick retraining of models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0031803834717720747 0.002321382286027074\n",
      "5000 0.00019503076327964664 0.00020559843687806278\n",
      "10000 0.00018478400306776166 0.00019718454859685153\n",
      "15000 0.00017277103324886411 0.00016304194286931306\n",
      "20000 0.0001336237764917314 0.00014334665320347995\n",
      "25000 0.00014024933625478297 0.00015149022510740906\n",
      "30000 0.00019689292821567506 0.0001466923567932099\n",
      "35000 0.00017193678650073707 0.00014605376054532826\n",
      "40000 0.00021374074276536703 0.00016108837735373527\n",
      "45000 0.00014638109132647514 0.00014709810784552246\n",
      "50000 0.0002198463334934786 0.00014388535055331886\n",
      "55000 0.00010754319373518229 0.00014504608407150954\n",
      "0 0.006560173816978931 0.005136239808052778\n",
      "5000 0.0001520379155408591 0.00020807882538065314\n",
      "10000 0.00018227485998068005 0.0002053323114523664\n",
      "15000 0.00019080998026765883 0.00017589540220797062\n",
      "20000 0.00024909223429858685 0.00017972012574318796\n",
      "25000 0.00021862657740712166 0.00016616580251138657\n",
      "30000 0.0002055289805866778 0.00016914571460802108\n",
      "35000 0.00022138954955153167 0.0001650527265155688\n",
      "40000 0.0001250110217370093 0.00016147004498634487\n",
      "45000 0.00011890705354744568 0.00015177212480921298\n",
      "50000 8.615148544777185e-05 0.00015302548126783222\n",
      "55000 0.0001541954989079386 0.00015879000420682132\n",
      "0.00014334665320347995 0.00015177212480921298\n"
     ]
    }
   ],
   "source": [
    "base_params = dict(d_hidden=256, lr=1e-4, weight_decay=0.0, batch_size=64, num_iters=60000, valid_interval=5000)\n",
    "\n",
    "model, sl_losses, fric_vals, fric_models = train_iid_model_param(buffer, True, **base_params)\n",
    "best_fric_idx = np.argmin(fric_vals)\n",
    "best_fric_model = fric_models[best_fric_idx]\n",
    "\n",
    "model, sl_losses, no_fric_vals, no_fric_models = train_iid_model_param(buffer, False, **base_params)\n",
    "best_no_fric_idx = np.argmin(no_fric_vals)\n",
    "best_no_fric_model = no_fric_models[best_no_fric_idx]\n",
    "\n",
    "print(fric_vals[best_fric_idx], no_fric_vals[best_no_fric_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.40416415, -0.38383759]]),\n",
       " array([[ 0.40727045, -0.38285544]]),\n",
       " array([[-1.54755801, -0.48495638]]),\n",
       " array([[-1.54224651, -0.4971875 ]]),\n",
       " array([[-0.87214636,  0.48924506]]),\n",
       " array([[1.00499471]])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.get_train_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09501904218349816 0.16255987130706637\n"
     ]
    }
   ],
   "source": [
    "test_T_start = N + 12345\n",
    "test_H = 15000\n",
    "\n",
    "trunc_idx = 0\n",
    "\n",
    "def set_fric_const(env, t):\n",
    "    env.set_floor_friction(1.4)\n",
    "\n",
    "# param_fn = set_friction_sin\n",
    "# param_fn = set_fric_const\n",
    "\n",
    "test_data = generate_data(param_fn, test_T_start, test_H)\n",
    "sim_states_prime, model_states_prime = rollout_model_single(best_no_fric_model, False, test_data['qpos'], test_data['qvel'], test_data['actions'], test_data['frictions'])\n",
    "seq_ssp = np.array(sim_states_prime)[trunc_idx:]\n",
    "no_fric_msp = np.array(model_states_prime)[trunc_idx:]\n",
    "_, model_states_prime = rollout_model_single(best_fric_model, True, test_data['qpos'], test_data['qvel'], test_data['actions'], test_data['frictions'])\n",
    "fric_msp = np.array(model_states_prime)[trunc_idx:]\n",
    "\n",
    "no_fric_x_err = np.average(np.sqrt(np.sum((seq_ssp[:, 0] - no_fric_msp[:, 0]) **2)))\n",
    "fric_x_err = np.average(np.sqrt(np.sum((seq_ssp[:, 0] - fric_msp[:, 0]) **2)))\n",
    "print(no_fric_x_err, fric_x_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871516014c3b4e1aaca0f63e3b2a54c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_idx = 0\n",
    "H = test_H\n",
    "%matplotlib widget\n",
    "vis_rollouts(seq_ssp[start_idx:start_idx+H], no_fric_msp[start_idx:start_idx+H], fric_msp[start_idx:start_idx+H], labels=['sim', 'no fric', 'fric'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's look at the sequential models vs the ones trained iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(model, set_param_fn, include_friction, T_start, H):\n",
    "    env = BoxEnv(set_param_fn=set_param_fn)\n",
    "    obs = env.reset()\n",
    "    t = 0\n",
    "    scale = 100\n",
    "    losses = []\n",
    "    frictions = []\n",
    "    features_all, labels_all = [], []\n",
    "    y_hats = []\n",
    "    xy_losses = []\n",
    "    xy_vel_losses = []\n",
    "    actions = []\n",
    "    while t < T_start + H:\n",
    "        \n",
    "        a = np.array([np.sin(t / scale), np.cos(t / scale)])\n",
    "        prev_obs = deepcopy(obs)\n",
    "        obs, rew, done, info = env.step(a)\n",
    "        actions.append(a)\n",
    "        \n",
    "        if t >= T_start:\n",
    "            xy = torch.from_numpy(obs[0:2]).float()\n",
    "            xy_prev = torch.from_numpy(prev_obs[0:2]).float()\n",
    "            xy_vel = torch.from_numpy(obs[3:5]).float()\n",
    "            xy_vel_prev = torch.from_numpy(prev_obs[3:5]).float()\n",
    "            act = torch.from_numpy(a).float()\n",
    "            friction = torch.from_numpy(np.array([env.get_floor_friction()])).float()\n",
    "\n",
    "            frictions.append(env.get_floor_friction())\n",
    "            pos_prev = torch.cat([xy_prev, xy_vel_prev])\n",
    "            if include_friction:\n",
    "                features = torch.cat([xy_prev, xy_vel_prev, act, friction])\n",
    "            else:\n",
    "                features = torch.cat([xy_prev, xy_vel_prev, act])\n",
    "\n",
    "            labels = torch.cat([xy, xy_vel])\n",
    "\n",
    "            features_all.append(features.numpy().copy())\n",
    "            labels_all.append(labels.numpy().copy())\n",
    "\n",
    "            y_hat = pos_prev + model(features)\n",
    "\n",
    "            y_hats.append(y_hat.detach().numpy().copy())\n",
    "            loss = F.mse_loss(y_hat, labels).item()\n",
    "            losses.append(loss)\n",
    "            xy_losses.append(F.mse_loss(y_hat[:2], labels[:2]).item())\n",
    "            xy_vel_losses.append(F.mse_loss(y_hat[2:], labels[2:]).item())\n",
    "            \n",
    "        t += 1\n",
    "    return losses, frictions, features_all, labels_all, y_hats, xy_losses, xy_vel_losses, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_start  = 0\n",
    "H = 10000\n",
    "# param_fn = set_friction_sin\n",
    "iid_fric_losses, frictions, features_all, labels_all, y_hats, iid_fric_xy_losses, iid_fric_xy_vel_losses, iid_actions = evaluate_models(best_fric_model, param_fn, True, T_start, H)\n",
    "iid_no_fric_losses, _,_,_,_, iid_no_fric_xy_losses, iid_no_fric_xy_vel_losses,_ = evaluate_models(best_no_fric_model, param_fn, False, T_start, H)\n",
    "seq_fric_losses, _,_,_,_, seq_fric_xy_losses, seq_fric_xy_vel_losses,_ = evaluate_models(large_include_learner.model, param_fn, True, T_start, H)\n",
    "seq_no_fric_losses, _,_,_,_, seq_no_fric_xy_losses, seq_no_fric_xy_vel_losses,_ = evaluate_models(large_no_include_learner.model, param_fn, False, T_start, H)\n",
    "seq_no_fric_losses_small, _,_,_,_, seq_no_fric_xy_losses_small, seq_no_fric_xy_vel_losses_small,_ = evaluate_models(small_no_include_learner.model, param_fn, False, T_start, H)\n",
    "\n",
    "true_ys = np.array(labels_all)\n",
    "pred_ys = np.array(y_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_rollouts3(rollout1, rollout2, vscale=1000, c1='r', c2='b'):\n",
    "    plt.scatter(rollout1[:,0], rollout1[:,1], marker='.', color=c1)\n",
    "    plt.scatter(rollout2[:,0], rollout2[:,1], marker='.', color=c2)\n",
    "    \n",
    "    for x, y, vx, vy in zip(rollout1[:,0], rollout1[:,1], rollout1[:,2], rollout1[:,3]):\n",
    "        plt.arrow(x, y, vx / vscale, vy / vscale, width=1e-4, color=c1)\n",
    "        \n",
    "    for x, y, vx, vy in zip(rollout2[:,0], rollout2[:,1], rollout2[:,2], rollout2[:,3]):\n",
    "        plt.arrow(x, y, vx / vscale, vy / vscale, width=1e-4, color=c2)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iid fric 0.0001344313377417616\n",
      "iid no fric 0.00014676076289391342\n",
      "seq fric 0.0001780582777878923\n",
      "seq no fric 0.0001936906676717996\n",
      "seq no fric small buf 0.00023260287857224853\n"
     ]
    }
   ],
   "source": [
    "print('iid fric', np.average(iid_fric_losses))\n",
    "print('iid no fric', np.average(iid_no_fric_losses))\n",
    "print('seq fric', np.average(seq_fric_losses))\n",
    "print('seq no fric', np.average(seq_no_fric_losses))\n",
    "print('seq no fric small buf', np.average(seq_no_fric_losses_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da03d19645a9403ea26fbdf75a498655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "xs = np.arange(len(iid_fric_losses))\n",
    "frictions = np.array(frictions)\n",
    "plt.plot(xs, iid_fric_losses, label='iid fric')\n",
    "plt.plot(xs, seq_fric_losses, label='seq fric')\n",
    "plt.plot(xs, seq_no_fric_losses, label='seq no fric')\n",
    "plt.plot(xs, seq_no_fric_losses_small, label='seq no fric small')\n",
    "plt.plot(xs, frictions/ 500.0)\n",
    "\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('prediction error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b55bc2ffdf640578062fce7a09b7cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_T = 290\n",
    "H = 30\n",
    "\n",
    "%matplotlib widget\n",
    "vis_rollouts3(true_ys[start_T:start_T+H], pred_ys[start_T:start_T+H])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "xs = np.arange(len(iid_fric_losses))\n",
    "frictions = np.array(frictions)\n",
    "acts = np.array(iid_actions)\n",
    "labs_np = np.array(labels_all)\n",
    "y_hats_np = np.array(y_hats)\n",
    "plt.plot(xs, iid_fric_losses, label='iid fric')\n",
    "plt.plot(xs, iid_fric_xy_losses, label='iid fric pos')\n",
    "plt.plot(xs, iid_fric_xy_vel_losses, label='iid fric vel')\n",
    "plt.plot(xs, frictions/ 500.0, label='friction')\n",
    "plt.plot(xs, acts[:, 0] / 250.0, label='actx')\n",
    "plt.plot(xs, acts[:, 1] / 250.0, label='acty')\n",
    "plt.plot(xs, labs_np[:, 0] / 250.0, label='x')\n",
    "plt.plot(xs, labs_np[:, 1] / 250.0, label='y')\n",
    "plt.plot(xs, labs_np[:, 2] / 250.0, label='vx')\n",
    "plt.plot(xs, labs_np[:, 3] / 250.0, label='vy')\n",
    "plt.plot(xs, y_hats_np[:, 2] / 250.0, label='vx_hat')\n",
    "plt.plot(xs, y_hats_np[:, 3] / 250.0, label='vy_hat')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('prediction error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21586235 0.21057317 1.3629992  0.5525674 ]\n",
      "[0.21565682 0.21040165 1.3917147  0.5513068 ]\n",
      "\n",
      "[0.2186111  0.21166795 1.3857601  0.5422261 ]\n",
      "[0.21841662 0.21160564 1.3839498  0.5401215 ]\n",
      "error shifted\t 0.019502629\n",
      "error orig\t 0.017273473\n"
     ]
    }
   ],
   "source": [
    "idx = 2712\n",
    "print(labs_np[idx])\n",
    "print(y_hats_np[idx])\n",
    "print()\n",
    "print(labs_np[idx+1])\n",
    "print(y_hats_np[idx+1])\n",
    "print('error shifted\\t', np.mean(np.linalg.norm(labs_np[:-1] - y_hats_np[1:], axis=1)))\n",
    "print('error orig\\t', np.mean(np.linalg.norm(labs_np - y_hats_np, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2157, 0.2104, 1.3917, 0.5513], grad_fn=<AddBackward0>)\n",
      "tensor([0.2184, 0.2116, 1.3839, 0.5401], grad_fn=<AddBackward0>)\n",
      "tensor([0.2211, 0.2126, 1.3908, 0.5304], grad_fn=<AddBackward0>)\n",
      "[[0.21306922 0.20945792 1.4001273  0.5626806 ]\n",
      " [0.21586235 0.21057317 1.3629992  0.5525674 ]\n",
      " [0.2186111  0.21166795 1.3857601  0.5422261 ]]\n"
     ]
    }
   ],
   "source": [
    "features = np.array(features_all)\n",
    "labels = np.array(labels_all)\n",
    "\n",
    "print(torch.from_numpy(features[idx][:4]) + best_fric_model(torch.from_numpy(features[idx])))\n",
    "print(torch.from_numpy(features[idx+1][:4]) + best_fric_model(torch.from_numpy(features[idx+1])))\n",
    "print(torch.from_numpy(features[idx+2][:4]) + best_fric_model(torch.from_numpy(features[idx+2])))\n",
    "print(features[idx:idx+3, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "tensor([ 0.4324, -0.4401])\n",
      "tensor([ 0.4350, -0.4386])\n",
      "tensor([-1.2471, -0.7176])\n",
      "tensor([-1.3119, -0.7344])\n",
      "tensor([-0.9949,  0.1005])\n"
     ]
    }
   ],
   "source": [
    "batch = buffer.get_train_batch(16)\n",
    "xy = torch.from_numpy(batch[0]).float()\n",
    "xy_prev = torch.from_numpy(batch[1]).float()\n",
    "xy_vel = torch.from_numpy(batch[2]).float()\n",
    "xy_vel_prev = torch.from_numpy(batch[3]).float()\n",
    "act = torch.from_numpy(batch[4]).float()\n",
    "friction = torch.from_numpy(batch[5]).float()\n",
    "\n",
    "pos_prev = torch.cat([xy_prev, xy_vel_prev], dim=1)\n",
    "features = torch.cat([xy_prev, xy_vel_prev, act] + ([friction] if include_friction else []) , dim=1)\n",
    "labels = torch.cat([xy, xy_vel], dim=1)\n",
    "\n",
    "y_hat = pos_prev + best_fric_model(features)\n",
    "loss = torch.mean(F.mse_loss(y_hat, labels,reduction='none'), dim=1)\n",
    "worst_loss = torch.argmax(loss, dim=0)\n",
    "print(loss[worst_loss])\n",
    "print(xy[worst_loss])\n",
    "print(xy_prev[worst_loss])\n",
    "print(xy_vel[worst_loss])\n",
    "print(xy_vel_prev[worst_loss])\n",
    "print(act[worst_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 443 is out of bounds for dimension 0 with size 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-d99db358c949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbig_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miid_fric_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m445\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_hat\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 443 is out of bounds for dimension 0 with size 16"
     ]
    }
   ],
   "source": [
    "big_errors = np.argwhere(np.array(iid_fric_losses) > 0.003)\n",
    "idx = 445 -2\n",
    "print('x\\t', features[idx])\n",
    "print('y\\t', labels[idx])\n",
    "print('y_hat\\t', y_hats[idx])\n",
    "print(F.mse_loss(torch.tensor(labels[idx]), torch.tensor(y_hats[idx])))\n",
    "print()\n",
    "print('x\\t', features[idx + 1])\n",
    "print('y\\t', labels[idx + 1])\n",
    "print('y_hat\\t', y_hats[idx + 1])\n",
    "print(F.mse_loss(torch.tensor(labels[idx+1]), torch.tensor(y_hats[idx+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_errors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a rollout using learned model vs sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14929578 1.15       1.15070422 ... 1.17896378 1.17827249 1.17758058]\n"
     ]
    }
   ],
   "source": [
    "# start_idx = 60000 + 2000 + 75\n",
    "# start_idx = 1000+200\n",
    "start_idx = 12324\n",
    "H = 50\n",
    "init_qpos = states['qpos'][start_idx]\n",
    "init_qvel = states['qvel'][start_idx]\n",
    "actions = states['actions'][start_idx:start_idx+H]\n",
    "fricts = states['frictions'][start_idx:start_idx+H]\n",
    "# frictions = [1.1] * H\n",
    "\n",
    "sim_states_prime, fric_model_states_prime = rollout_model(best_fric_model, True, init_qpos, init_qvel, actions, fricts)\n",
    "_, no_fric_model_states_prime = rollout_model(best_no_fric_model, False, init_qpos, init_qvel, actions, frictions)\n",
    "ssp = np.array(sim_states_prime)\n",
    "fmsp = np.array(fric_model_states_prime)\n",
    "nfmsp = np.array(no_fric_model_states_prime)\n",
    "print(frictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049bd9e303b24955b4c36efcfd3091b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "vis_rollouts(ssp, fmsp, nfmsp, labels=['sim', 'fric iid', 'no fric iid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4830e1cb11f49179e58ec0c4a4b3dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, buf = rollout_model(small_include_learner.model, True, init_qpos, init_qvel, actions, frictions)\n",
    "# _, buf = rollout_model(small_no_include_learner.model, False, init_qpos, init_qvel, actions, frictions)\n",
    "# _, buf = rollout_model(large_include_learner.model, True, init_qpos, init_qvel, actions, frictions)\n",
    "# _, buf = rollout_model(large_no_include_learner.model, False, init_qpos, init_qvel, actions, frictions)\n",
    "\n",
    "nfsb = np.array(buf)\n",
    "%matplotlib widget\n",
    "vis_rollouts(ssp, nfsb, nfmsp, labels=['sim', 'no fric seq small', 'no fric iid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vel_idx = np.argmin(np.linalg.norm(seq_ssp[:, 1], axis=1))\n",
    "print(seq_ssp[min_vel_idx, 1])\n",
    "print(seq_ssp[:, 1])\n",
    "print(np.linalg.norm(seq_ssp[:, 1], axis=1))\n",
    "print(np.linalg.norm(seq_ssp[min_vel_idx, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data['frictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model = new_model()\n",
    "lr=1e-4\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "learner = Learn(model, optim, F.mse_loss)\n",
    "\n",
    "obs = env.reset()\n",
    "t = 0\n",
    "scale = 100\n",
    "while t < T:\n",
    "    a = [np.sin(t / scale), np.cos(t / scale)]\n",
    "    prev_obs = obs\n",
    "    obs, rew, done, info = env.step(a)\n",
    "\n",
    "    process(buffer, learner, env, prev_obs, obs, a, t)\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = []\n",
    "vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    trains.append(buffer.get_train_batch(40*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    vals.append(buffer.get_val_batch(40*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = buffer.get_train_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_first = []\n",
    "for batch in trains:\n",
    "    all_first.append(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trains = np.concatenate(all_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trains = np.unique(all_trains, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vals = np.concatenate(all_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals = np.unique(all_vals, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trains.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not set(list(unique_trains[:,0])).isdisjoint(set((unique_vals[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
